\documentclass[sigconf,authordraft]{acmart}
\usepackage{tabularx}

\newcommand{\etal}{{\itshape et al}}

% \documentclass[sigconf,authordraft]{acmart} gives same document but with line numbers and "unpublished draft" watermark across whole page

%%%% Proceedings format for SIGPLAN conferences 
% \documentclass[sigplan, anonymous, authordraft]{acmart}

%%%% Proceedings format for conferences using one-column small layout
% \documentclass[acmsmall,authordraft]{acmart}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2020}
\acmYear{2020}
\acmDOI{10.1145/1122445.1122456}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[NSPW 2020]{New Security Paradigms Workshop 2020}{26-29 October 2020}{North Conway, NH}
\acmBooktitle{New Security Paradigms Workshop '20, October 26--29, 2020, North Conway, NH}
\acmPrice{0.00}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting the next command will enable that style.
%%\citestyle{acmauthoryear}

\begin{document}


\title{Social Friction and Decentralization in Online Communities}

%

\author{Joel Miller}
\affiliation{%
  \institution{UIC}
}
\email{jmill54@uic.edu}

\author{Chris Kanich}
\affiliation{%
  \institution{UIC}
}
\email{ckanich@uic.edu}






% % % Abstract

\begin{abstract}
OUTLINE:
\begin{enumerate}
    \item Introduction: the internet has been used for some bad stuff. Political discussions are kind of a mess.\\
    \item Here's this idea of social friction. it exists in the real world and it's helpful there. Here's why it deserves to be its own term, instead of other stuff sociologists have already talked about.\\
    \item Does social friction exist on the internet? Not really. Most research on keeping bad folks out (e.g. sybil attacks) is reactive, in the context of social networks at least. (\textit{new subsection}) So we should build friction into social networks.\\ 
    \item Here are two existing social networks, Mastodon and Nextdoor, that both partially get at what we're trying to do. The way admin/hosting priveleges are distributed is really important in empowering communities to put social friction around themselves. We could also build friction on top of other networks. \\
    \item Here's a taxonomy of social networks and some analysis of it. \\
    \item Here's some experiments we'll do in the future.\\
    \item Conclusion \\
\end{enumerate}
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% 

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10002978.10003029</concept_id>
       <concept_desc>Security and privacy~Human and societal aspects of security and privacy</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Security and privacy~Human and societal aspects of security and privacy}

% end of copied code from http://dl.acm.org/ccs.cfm.

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{social networks, sybil attacks}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}

\textit{(NOTE: maybe start by talking about times when social media was good (arab spring?) then hit `em with the ``BUT...'')}

Much recent popular discourse has focused on the threats that {\itshape bots} (automated or semi-automated social media accounts) pose to healthy discussion on social media networks. Boshmaf \etal found that Facebook was quite vulnerable to large-scale infiltration by botnets and created a botnet capable of befriending up to 80 percent of targeted users \cite{boshmaf2013design}, leading to serious privacy and security concerns. On twitter, Messias \etal show that botnets can game the microblogging service to artificially raise the influence of some users \cite{messias2013you}. Meanwhile, experimental evidence shows that emotional states spread within social networks \cite{kramer2014experimental}, which in turn suggests that botnets which gain access to large swaths of a network can influence the emotions of real users through the spread of inflammatory content. 

In the American political and media landscape, much attention has been given to the role of bots, propaganda, foreign influence, and unauthorized data collection in the 2016 presidential election. Between election day and January 2018, Twitter found 50,258 bot accounts which tweeted political content during the election period and were linked to foreign actors \cite{Twitter2016BotReport}. In the same vein, an investigation by United States special counsel Robert Mueller found that foreign actors sought to influence the outcome of the election, partially through various social media campaigns \cite{mueller2019report}, and Bessi \etal used the bot-detection program {\itshape BotOrNot} \cite{davis2016botornot} to estimate that bots accounted for around one fifth of generated content in the political discussion leading up to the 2016 election \cite{bessi2016social}. Several other studies have  produced evidence that bot activity and propaganda significantly effected social media discussions in advance of the 2016 election \cite{howard2017junk, badawy2018analyzing, woolley2017computational, shao2018spread}. The months preceding the election also saw a surge in unauthorized data collection that was used to create targeted political ads \cite{CambridgeAnalyticaNYT}.

However, the notion of using human or automated accounts spreading propaganda via social media is not unique to the 2016 election: countries around the world deploy ``cyber troops'' to influence online discussions \cite{bradshaw2017troops}, and Ratkiewicz \etal found that botnets were used to spread political content in advance of the 2010 US Midterm elections as well \cite{ratkiewicz2011truthy}.

Misuse of social media tools can also lead to the unraveling of social movements. Writing of the 2011-2012 Indignados protests in Spain \cite{indignadosBBC}, Rone finds that trolling behavior, the hijacking of social media accounts, the manipulation of voting systems, and the creation of fake accounts to infiltrate closed groups were all significant factors contributing to the dissolution of the movement \cite{rone2019fake}. Social networks have also been used to radicalize people to terrorist organizations \cite{o2007virtual,Torok2016SocialMA}. All in all, social media has become a hotbed for manipulation and disinformation \cite{benkler2018network}.

All of this evidence suggests that current popular social media platforms (e.g. Facebook and Twitter) may not be the perfect place to have political or otherwise sensitive discussions. In this paper, we seek to understand why this is the case, and what qualities of a social network may make it more robust to bad-faith influence. Importantly, we aim to challenge the longstanding belief that the internet should be as open as possible across all application domains. 

The rest of the paper proceeds as follows. In section 2, we define the notion of \textit{social friction}, show its connections to anthropology and sociology, and discuss how it can act as a security mechanism that keeps unwanted outsiders from joining said social groups. In section 3 we examine the ways in which social friction manifests itself on the internet, critically analyze the effect that mainstream perceptions of the internet have on the ability of bad-faith actors to spread propaganda and disinformation, and propose that allowing social friction to play a greater role in online networks could mollify some of these problems. In section 4, we discuss two already-existing social networks, Mastodon and Nextdoor, which each satisfy some of the desiderata we see as integral to our model of social friction in online spaces. We conclude by giving a taxonomy of social networks according to the lines along which we analyze them throughout the paper, and propose future work to empirically validate our arguments.  


% \section{Related work}
% Morris {\itshape et al} \cite{morris2002schmooze} use the term ``social friction'' in a manner similar to ours in a study examining the extent to which introductory phone calls eased awkwardness in email negotiations between two parties who did not previously know each other. 

\section{Social Friction}

\textit{(
NOTE: when I started doing the lit review for this paper, my main goal with this section was to give social friction a grounding in sociology/anthropology that gave it more credibility. I haven't been able to find any literature that exactly mapped to the concept. I suppose that this section seeks to justify the introduction of ``social friction'' as a new term instead, while still showing its connections to the humanities)}

We use the term {\itshape social friction} to describe the natural barriers to entry an individual may face when joining a community. If the community is a group of friends, a newcomer seeking to join the friend group will need to gain the trust of the group before they are accepted. If the community is a town, a newcomer must buy or rent property in that town to be considered a resident. If the community is a family, then a newcomer must marry a family member (or be born of a family member) to be considered a member of that family. In each of these scenarios, a newcomer to the community needs to meet certain criteria (accruing trust, buying property, courtship and marriage) before they can attain community membership. We use the term {\itshape social friction} to describe the challenges encountered in meeting those criteria. 

Social friction is related to the concepts of \textit{social barriers} and \textit{rites of passage} from Anthropology and Sociology. {\itshape Social barriers} are used broadly in the literature to describe non-technological hindrances that make it more difficult for an individual or group to complete an action, whether that action be joining a social movement \cite{klandermans1987potentials}, visiting a city park \cite{cutts2009city}, accepting a new energy source\cite{pasqualetti2011social}, or achieving economic empowerment\cite{woolcock2000removing}. The varied contexts in which the idea of a social barrier appears highlight a key difference between that term and our idea of social friction: scope. A social barrier can refer to a broad set of phenomena, whereas social friction is more specific. In fact, one could think of social friction as the specific social barriers that hinder an individual from joining a community (rather than, say, accepting a new energy source). 

We also seek to distinguish the idea of social friction from the idea of social barriers in an attitudinal sense \textit{(NOTE: there has got to be a better word than ``attitudinal'' to use here...)}. In the papers we encountered during our literature review, a social barrier was always framed by the authors as something negative that should be torn down if possible, and with good reason -- many of these social barriers did indeed stand in the way of positive changes. But we do not see social friction as an inherently negative phenomenon. In fact, social friction is beneficial to communities in so far as it provides a natural vetting process against potentially malicious outsiders. Imagine, for example, if any stranger could walk into your house and announce themselves as a new member of your family -- you may have some doubts about that stranger's intentions. Social friction (manifesting here as the requirement that this stranger gain the trust and love of an unmarried family member before joining the family) is what keeps such a thing from happening. 

The idea of social friction also bears similarity to the idea of a rite of passage, which emerged from Anthropological research and has since seen use in other disciplines \cite{blackwell_ROP,guha2011routledge}. However, if social barriers are too broad of a concept to mesh well with our idea of social friction, rites of passage are instead too specific. A rite of passage denotes a well-defined ritual which occurs at a specific point in time, whereas the actions needed to overcome social friction (e.g. gaining trust) are not necessarily demarcated by any one event and can occur gradually over time. Nevertheless, some of the actions necessary to overcome social friction could be seen as rites of passage (e.g. a meeting to finalize the purchase of a house), so there is some overlap between the two concepts. 

One can see social friction as a mechanism through which communities can provide security for themselves -- a tool wielded by community members to make sure that only people they trust join the community. Furthermore, one can notice that the amount of social friction needed to join a community is often correlated with the amount of harm that an unwanted community member could cause: joining a house party is a process with relatively little friction, whereas joining a family is a high-friction process. If we consider social friction as a source of security for communities, this correlation makes perfect sense: it is natural to put more effort into protecting something that is more valuable.

\section{Friction on the internet?}

In our view, online communities exhibit relatively little social friction. Any twitter account can tweet at any other account, as long as both are public. Facebook friend requests are accepted with relative ease in comparison to the effort involved in forming an offline friendship, and the same could be said of acceptance into a Facebook group.

The relative openness of these platforms should come as no surprise when one considers the context they were built in in: the internet has been (rightly) praised for, and achieved global relevance due to the way in which it allows ideas and artifacts to travel between people and communities with relatively little hindrance. In general, openness is a defining characteristic of the internet \cite{bechmann2014ubiquitous, lessig2002future}. That attitude has accordingly manifested itself in the domain of social networks: a recent survey of Sybil attack defenses in social networks cites openness as a fundamental property of online social networks \cite{al2017sybil}.

Turning our attention back to the problems plaguing social networks, we see that most research on botnet detection and sybil attack defense in the context of social networks follows this ideological trend: many proposed solutions are {\itshape reactive} in nature, meaning that the authors take the openness of the system as a given, and build tools to figure out which actors within it are bots/ sybil identities. Of the 19 techniques surveyed in a 2017 IEEE article \cite{al2017sybil}, all but three \cite{yu2006sybilguard,yu2008sybillimit,Tran2011Gatekeeper} were reactive in nature. However, foundational research on Sybil attacks suggests that a reactive approach less effective compared to approaches that gate who can enter the community, except under exceedingly rare circumstances \cite{douceur2002sybil}.



These approaches aside, the presence of bots is not the  only factor contributing to the political disarray of most social networks: real humans (``cyber troops'') can also take up the task of spreading disinformation and propaganda, sometimes for pay \cite{bradshaw2017troops}. Also problematic are the data collection practices of firms that use personal data to create targeted political messaging. The public's negative response to such practices are perhaps best exemplified in the Facebook-Cambridge Analytica scandal \cite{CambridgeAnalyticaNYT}. Neither of these problems can be classified as sybil attacks, but both of them involve bad-faith actors either giving (in the case of cyber troops) or taking (in the case of data collection) information to/from a user in a way that is not necessarily respectful of the user's views nor in the spirit of healthy discourse. In both cases, the relative openness of online spaces is what allows these transgressions to occur.

At the end of the previous section, we noted an anecdotal correlation between the amount of social friction around a real-world community and relative harm a malicious outsider could do to that community, were they able to gain membership. Given the turmoil caused by digital interference in social networks and the material implications of political decisions that are partially informed by social media landscapes, it would appear that many online communities do not fit with in with this trend -- that is to say, they have low social friction, but unwanted actors who enter can cause a lot of harm. 

Overall, we worry that in the context of social media, and more specifically in the context of social media discussions related to politics, the openness of the internet has allowed for more harm than good. Specifically, we feel that the idea that any user can receive incoming information from any other source has been abused by malicious parties who inundate regular users with so much bad-faith information that distinguishing between the good from the bad, real people and credible sources from bots and disinformation, is all but impossible.

Accordingly, we propose that introducing friction to online communities, specifically communities centered around politics or otherwise sensitive topics, could be an effective way to combat bad-faith behavior, whether that behavior be Sybil attacks, intrusions from unwanted cyber-troops, or unauthorized data collection. Instead of letting an arbitrary number of bad actors enter online spaces and then trying to weed them out, we propose a framework under which those bad actors are kept from joining online spaces in the first place. In the following sections, we examine existing social networks to understand what which of their qualities could contribute positively to such a framework.


\section{Qualities of networks that support social friction}

\subsection{Mastodon and Distributed Administration/ Community Hosting}

Mastodon\footnote{\url{https://joinmastodon.org/}} is microblogging service similar to Twitter. Users share short messages called ``toots'' (an analog to Tweets) which they can favorite, reply to, and ``boost'' (an analog to Twitter's retweet functionality). Mastodon does not have the recommendation features that Twitter has (i.e. ``who to follow'' suggestions), but recent work has shown that implementing recommender systems on top of Mastodon is possible \cite{trienes2018recommending}. Like Twitter, Mastodon is primarily developed by a centralized team. However, Mastodon's software is open source.

The major difference between Mastodon and Twitter (and most other social networks) is the radical {\itshape (NOTE: ``radical'' too much here?)} nature in which its communities and administrative privileges are distributed. Mastodon is made up of many interconnected servers, each hosted by an individual or party who need not be connected to the developers of Mastodon, and when a user joins Mastodon they choose a specific server to join (although they can migrate their content to an account on another server later if they so choose). In general, there is nothing stopping a user on one server from interacting with a user on another server {\itshape a priori}. Moreover, the developers of Mastodon hold none of the administrative privileges. Instead, the parties who run each individual mastodon server have administrative priveleges over what goes on on their server, including power over who is allowed to join and who is allowed to see posts on the server. In this way, Mastodon is decentralized with respect to its distribution of administrative privileges and its distribution of server-hosting responsibility.

This naturally allows for a framework by which communities can create social friction around themselves. Specifically, each server is free to set their own guidelines on who is allowed to enter. These guidelines can be social (e.g. community members discuss whether or not they want to let the outsider in), technological (e.g. a user is let into the server that residents of a town use to talk local politics if they can provide a crpytographic proof of their residence in the town), or a mix of both. 

Letting communities set their own security and membership guidelines has another advantage: it reduces the scalability of attacks. Any bot-detection algorithm implemented by an open social network like twitter will have the drawback that an any successful evasion of the algorithm will scale quite well. That is to say, since all communities on twitter are uniform with regards to their protection under a bot-detection algorithm, a strategy for evading the algorithm in one community will also work in any other community. In contrast, letting every decentralized server create their own membership requirements is a security strategy that will not lend itself well to wide-scale attacks. Since each server is encouraged to customize their membership requirements, an attack that works well on one server is by no means guaranteed to work on any other server. This is an important advantage because it greatly reduces the economic efficiency of any potential attack. Moreover, since under our model the development privileges are still centralized, the developers of a system like Mastodon could still create a bot-detection algorithm and let servers adopt it for an extra layer of security.

Lastly, we note that letting the developers of a social media network hold administrative privileges represents an potential conflict of interest with regards to the curtailing of bots and propaganda. Specifically, barring the negative effects of public outrage over heavily publicized scandals involving bots and propaganda, one might imagine that from the developers' perspective, bot activity and propaganda is good for business. Inflammatory content is shared with higher frequency on social media \cite{stieglitz2013emotions}, and bots are more likely to share inflammatory content \cite{stella2018bots}. Therefore, if one measures the success of a social network by the amount of traffic its users generate, then it would appear that curtailing bots might not always be in the best economic interests of the managers of the network. Of course, it is also possible that a period of intense public backlash to bot activity constitutes a financial threat more severe than the financial gain of allowing bots, and in this case the developers of a social network would instead be incentivized to crack down on bot activity. But in either case, centralizing a network's administrative privileges to the same people who run the network leads to scenarios in which the administrators wield those privileges in the way that will provide them with the most financial benefit, rather than the way that will create the best discursive environment.

We do not mean to suggest that Mastodon in particular needs to become the center of research or development efforts centered around social friction -- only that its operational model, and specifically its decentralization of administration and hosting responsibilities, has many potentially positive qualities with regard to enabling high-quality deliberation.

\subsection{Nextdoor and location-specific networks}

Given that we propose geographically-based communities as a main use-case for the idea of social friction, we now briefly discuss Nextdoor \footnote{\url{https://nextdoor.com/}}, a social network site tailored for individual neighborhoods.

Nextdoor is a popular current social networking site where users join neighborhood-specific communities. In order to join one such community, a user must either send Nextdoor a picture of their driver's license or enter a code on a postcard mailed to their address. In this way, Nextdoor centralizes an important administrative privilege (the power to decide who can join a neighborhood's network), although power users can gain some other administrative privileges. Unlike Mastodon, Nextdoor also centralizes hosting responsibility.

Masden {\itshape et al} conducted interviews with 13 Nextdoor users across various neighborhoods in a metropolitan area and found that participants reported strong community engagement and ``a lack of divisive or combative content'' on the platform, however they also reported that privacy concerns and disagreements about the boundaries of specific neighborhoods were a cause for tension \cite{masden2014tensions}. We are heartened by Masden's positive findings, and feel that participants' anxieties about privacy and neighborhood boundaries could largely be mollified in a decentralized system that offered increased privacy protections (partially possible due to a reduced need to please advertisers) and the ability for self-sovereign communities to change their boundaries over time, rather than having those boundaries controlled by a centralized source.

On the other hand, Kurwa conducted an exploratory analysis in which he found that Nexdoor ``has become an important platform for the surveillance and policing of race in residential space'' \cite{kurwa2019building}. In section 7, we outline future work to better understand this phenomenon and the extent to which it is endemic to neighborhood-specific online communities.

We also note that the entry requirements Nextdoor places on its users are perhaps at the upper bound of how strict a community could be about its entrance requirements -- in the world of social friction, these requirements may be analogous to very course sandpaper. We imagine a network of communities in which each community is free to define its own membership requirements, and for a geographically-based community, those membership requirements could be a proof of residence, but they could also be something more lenient. For example, an online community centered around a town may allow people from that town as well as neighboring towns to join, or it might allow past residents to join, or residents from a neighboring town that at least $n$ residents can vouch for, etc. 

In section 7, we also outline future work to leverage cryptography (specifically zero-knowledge proofs) to allow users to make statements like ``I spend at least 50 percent of my time in this town'', which could be used as inputs into a community's scheme of entrance requirements. Zero-knowledge proofs of statements like this could be especially useful with respect to more complicated geographic situations where a user's place of residence does not necessarily reflect the entire scope of their political interests. For example, one could imagine a situation where many people live in area $A$ but commute to area $B$ for work -- perhaps these people should have a say in discussions about the economic policies of area $B$. Nextdoor does not support  this type of fine grained and community-specific specialization of entrance requirements.

Overall, although some research Nextdoor is hopeful with regards to the discursive environments of geographically-centered online networks, we ultimately seek a system with more flexibility than what Nextdoor provides. Furthermore, we note that Nextdoor's centralization of administrative capability is likely a factor contributing to its inflexibility of entrance requirements across communities -- for a centralized team, it is much more economical to create one set of entrance requirements that can be applied in any context.

\section{overlaying friction on other social networks}

The idea of social friction can also be used to build overlays on other social networks. For example, one could imagine a tool that lets Twitter users define their own metric of trust relative to another user (e.g. number of followers in common, distance away in the follow graph, etc) and augments the user's twitter feed by only showing the user tweets from other users who attain a threshold trust score, under whatever metric the user defines. Since each user is free to customize their own metric of trust, we gain an advantage from decentralization similar to the advantage gained by letting each individual Mastodon server set its own membership rules. That is to say, for users Alice and Bob, a strategy that lets an attacker many bots that can unfairly gain Alice's trust will not necessarily succeed in creating bots that can unfairly gain Bob's trust.

But we also note that it might not be appropriate to incorporate the idea of social friction into every online network. Specifically, we see social friction as being extremely useful to the operation of online deliberation \cite{semaan2015designing} and participatory budgeting platforms \cite{de1998participatory,shah2007participatory,wampler2010participatory,cabannes2004participatory}, via which participants can debate each other and vote on policy decisions or recommendations. Importantly, in the context of political discussion, we do not necessarily wish to create communities that are divided along political lines, but communities free of bad-faith outsiders who wish to sway the conversation in one direction or another. 

A fitting analog might be the idea of Deliberative Democracy first proposed by Fiskin \cite{fishkin1991democracy}, which has manifested most recently in the America in One Room project \cite{AmericaInOneRoom}. This project saw Americans from all walks of life invited to a central location in Texas where they debated topics germane to American politics topics with each other. The organizers of this event did not seek to exclusively invite participants with a specific political orientation, but they {\itshape did} seek to only invite participants who were from America, given that the event was centered around debating American politics. In the same way, our hope is that online deliberation platforms can use social friction to keep out bad-faith outsiders while still allowing for healthy political debate.

\section{a taxonomy of social networks}

In order to better understand the axes along which various social networks are centralized or decentralized, we have taxonomized several popular social networks  (Table \ref{tab:taxonomy}).

%%% Link to taxonomy in my google drive : https://docs.google.com/spreadsheets/d/1Q9rg_i6YAEYkcFf2JBfe5wJIKaecT4_MpXmSPnUIFSE/edit#gid=0

\begin{table*}
  \caption{A taxonomy of online networks}
  \label{tab:taxonomy}
  \begin{tabularx}{\textwidth}{llXX}
    \toprule
    Platform & Centralization of source code & Centralization of administrative privileges & Centralization of community hosting \\
    \midrule
    Twitter  & Centralized & Centralized\\
    Facebook & Centralized & Semi-centralized: moderators of Facebook groups have some administrative privileges & Centralized\\
    Reddit   & Centralized & Decentralized & Centralized  \\
    Slack/ discord & Centralized & Decentralized & Centralized \\
    Group Chats & Centralized & N/A -- no one has administrative privileges & Centralized \\
    Mastodon & Decentralized (open source) & Decentralized & Decentralized\\
    Nextdoor & Centralized & Semi-centralized: power users can gain some administrative privileges & Centralized \\
    Blockchain Apps & Decentralized (open source) & N/A -- application-dependent & Decentralized\\
    \bottomrule
  \end{tabularx}
\end{table*}

Of these networks, three have decentralized administrative privileges (Reddit, Slack/Discord, and Mastodon), and of those three only Mastodon is decentralized with regards to community hosting. But without decentralized community hosting, administrative privileges cannot be truly decentralized, since the power given to administrators can still be altered by the central entity who hosts all the communities. For example, there is nothing stopping Reddit from changing its policy on subreddit administration and transferring some moderator power to a centralized in-house team.

We can also see the ``report'' functions on Twitter and Facebook (via which anyone can flag an inappropriate post for moderator review) as an attempt to distribute some administrative capability throughout the network. However, any reports made under such a scheme must still pass through a centralized bottleneck of in-house moderators. 

\section{Future Work}

We hypothesize that the centralization or decentralization of a network's administrative privileges and hosting ability has a profound impact on the way information flows in that network and the amount of social friction communities can are able create around themselves. Moreover, we hypothesize that allowing communities to establish social friction around themselves will lead to richer and more productive deliberatory experiences inside said communities.

Our future work will have two main goals: to validate our hypothesis that increased social friction can benefit communities involved in political discussions, and to design technological mechanisms that will enable communities to create social friction around themselves in online spaces. 

To test our hypothesis on the effectiveness of social friction, we will conduct studies that measure the quality of conversations across online communities that exhibit various amounts of social friction. One promising set of communities to examine are Reddit's ``subreddits'', many online communities each with their own sets of rules.

On the technological side, we have begun to design a privacy-preserving cryptographic protocol which uses zero-knowledge proofs \cite{goldreich1991proofs} to allow agents to show that certain facts about their average location over time. Such a system could be used to let users create online communities for discussions germane to a certain geographic area where only the residents of that geographic area can participate, while still respecting the privacy of all participants.

\section{Conclusion}

We have presented a new viewpoint on security that seeks to question the de-facto acceptance of the internet's openness. We suggest that in certain scenarios, the openness of the internet has the potential to do more harm than good, and that this argument is supported by recent events in American politics. To further support that hypothesis, we define the notion of social friction and consider the ways in which it can be seen as a tool that communities can use to provide security for themselves. We examine the structures of different social networks, creating a taxonomy along which different networks are classified according to how they distribute development, administrative, and hosting responsibilities. We hypothesize that networks with decentralized administrative and hosting responsibilities are more likely to support communities guarded by social friction, and hypothesize that such communities will be more conducive to high quality discussion. Our goal is to validate those hypothesis via experimental evidence, and to design technological mechanisms that will enable social friction.

% \begin{acks}
% The authors would like to thank Emma Hanlon and Gabriel Eisen for helpful discussions about Sociology and Anthropology.
% \end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography}


\end{document}
\endinput